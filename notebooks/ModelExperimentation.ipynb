{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import string\n",
    "\n",
    "import mlflow\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path().resolve().parents[0]\n",
    "MODEL_REGISTRY = Path(\"/tmp/mlflow\")\n",
    "Path(MODEL_REGISTRY).mkdir(parents=True, exist_ok=True)\n",
    "MLFLOW_TRACKING_URI = str(ROOT_DIR) + str(MODEL_REGISTRY.absolute())\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "# print(f\"MLFLOW_TRACKING_URI: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"test_arabic_negative_tweets\": \"../data/test_arabic_negative_tweets.tsv\",\n",
    "    \"test_arabic_positive_tweets\": \"../data/test_arabic_positive_tweets.tsv\",\n",
    "    \"train_arabic_negative_tweets\": \"../data/train_arabic_negative_tweets.tsv\",\n",
    "    \"train_arabic_positive_tweets\": \"../data/train_arabic_positive_tweets.tsv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str, label: int) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from a TSV file and changing it to a CSV file to easily read from.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the TSV file.\n",
    "        label (int): The label to assign to each tweet (0 for negative, 1 for positive).\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: A Polars DataFrame containing tweets and their labels.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(file_path, newline=\"\", encoding=\"utf-8\") as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            rows.append([row[1], label])\n",
    "    return pl.DataFrame(rows, schema=[\"tweet\", \"label\"])\n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess a tweet by removing mentions, URLs, punctuation, emojis, diacritics,\n",
    "    and extra spaces, normalizing Arabic text, and removing repeated characters.\n",
    "\n",
    "    Args:\n",
    "        text (str): The tweet text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned and normalized tweet text.\n",
    "    \"\"\"\n",
    "    arabic_diacritics = re.compile(\n",
    "        \"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "\n",
    "                         \"\"\",\n",
    "        re.VERBOSE,\n",
    "    )\n",
    "\n",
    "    arabic_punctuations = \"\"\"`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ\"\"\"\n",
    "    english_punctuations = string.punctuation\n",
    "    punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "\n",
    "    text = re.sub(arabic_diacritics, \"\", text)\n",
    "\n",
    "    translator = str.maketrans(\"\", \"\", punctuations_list)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    text = re.sub(r\"(.)\\1+\", r\"\\1\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tweet</th><th>label</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;كل الي تمنينه يا فلانه ان في ش…</td><td>1</td></tr><tr><td>&quot;رحمة الله الواسعة عليه ربي يجع…</td><td>1</td></tr><tr><td>&quot;فيها كرت أصفر ثاني .. بعد اصاب…</td><td>1</td></tr><tr><td>&quot;تلاتين سنة بترقص .. الليلة رقص…</td><td>0</td></tr><tr><td>&quot;تموتت 😭💔💔 اللي حابه تسوي اضاءة…</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ tweet                           ┆ label │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i64   │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ كل الي تمنينه يا فلانه ان في ش… ┆ 1     │\n",
       "│ رحمة الله الواسعة عليه ربي يجع… ┆ 1     │\n",
       "│ فيها كرت أصفر ثاني .. بعد اصاب… ┆ 1     │\n",
       "│ تلاتين سنة بترقص .. الليلة رقص… ┆ 0     │\n",
       "│ تموتت 😭💔💔 اللي حابه تسوي     ┆ 1     │\n",
       "│ اضاءة…                          ┆       │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg = load_data(file_paths[\"train_arabic_negative_tweets\"], 0)\n",
    "train_pos = load_data(file_paths[\"train_arabic_positive_tweets\"], 1)\n",
    "test_neg = load_data(file_paths[\"test_arabic_negative_tweets\"], 0)\n",
    "test_pos = load_data(file_paths[\"test_arabic_positive_tweets\"], 1)\n",
    "\n",
    "train_df = pl.concat([train_neg, train_pos])\n",
    "test_df = pl.concat([test_neg, test_pos])\n",
    "df = pl.concat([train_df, test_df])\n",
    "df = df.sample(fraction=1, shuffle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    [\n",
    "        pl.col(\"tweet\")\n",
    "        .map_elements(preprocess_text, return_dtype=str)\n",
    "        .alias(\"cleaned_tweet\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>label</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>28513</td></tr><tr><td>28282</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2,)\n",
       "Series: 'label' [u32]\n",
       "[\n",
       "\t28513\n",
       "\t28282\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"cleaned_tweet\"].to_numpy()\n",
    "y = df[\"label\"].to_numpy()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf=True, norm=\"l2\", smooth_idf=True)\n",
    "X_tfidf = tfidf.fit_transform(vectorizer.fit_transform(X)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, stratify=y, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, labels):\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.savefig(\"./dump/confusion_matrix.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7823752090853068\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      5656\n",
      "           1       0.80      0.76      0.78      5703\n",
      "\n",
      "    accuracy                           0.78     11359\n",
      "   macro avg       0.78      0.78      0.78     11359\n",
      "weighted avg       0.78      0.78      0.78     11359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"MultinomialNB Experiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"MultinomialNB\")\n",
    "\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    for label, metrics_dict in report.items():\n",
    "        if isinstance(metrics_dict, dict):\n",
    "            for metric_name, metric_value in metrics_dict.items():\n",
    "                mlflow.log_metric(f\"{label}_{metric_name}\", metric_value)\n",
    "\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    unique_labels = list(set(y_test))\n",
    "    plot_confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "    mlflow.log_artifact(\"./dump/confusion_matrix.png\")\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{metrics.classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proper_format(text: str):\n",
    "    text = preprocess_text(text)\n",
    "    vectorized_text = vectorizer.transform([text])\n",
    "    transformed_text = tfidf.transform(vectorized_text)\n",
    "    return transformed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(get_proper_format(\"ولان بعض الحال يصعب شرحه اثرت صمتا والسكوت مرير\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(get_proper_format(\"الله يقلع ام الهلال خرب ام الدوري\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.predict(get_proper_format(\"انست بوحدتي ولزمت بيتي فطاب الانس لي وصفا السرور\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./models/nb_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump((vectorizer, tfidf, model), file)\n",
    "\n",
    "# with open(\"./models/vectorizer.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(vectorizer, file)\n",
    "\n",
    "# with open(\"./models/tfidf_transformer.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(tfidf, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faheem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
